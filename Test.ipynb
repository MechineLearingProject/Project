{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(575, 20)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def tf(x):\n",
    "    if x == \"TRUE\" :\n",
    "        return 1\n",
    "    elif x == \"FALSE\" :\n",
    "        return 0\n",
    "    else :\n",
    "        return 0.5\n",
    "def lg(x):\n",
    "    return np.log10(x+1)\n",
    "\n",
    "#import data\n",
    "training_data = pd.read_csv('training_data_2_csv_UTF.csv')\n",
    "testing_data = pd.read_csv('test_data_4_students.csv')\n",
    "testing_data = testing_data.head(575)\n",
    "result = pd.DataFrame(testing_data['id'])\n",
    "result.insert(1,'bot',0)\n",
    "result['id'] = result['id'].astype(int)\n",
    "print(testing_data.shape)\n",
    "training_data.insert(4,'des_bot',0)\n",
    "training_data.loc[pd.notnull(training_data['description']) & training_data['description'].str.contains(\"bot|Bot|BOT\"), 'des_bot'] = 1\n",
    "training_data.insert(5,'name_bot',0)\n",
    "training_data.loc[pd.notnull(training_data['name']) & training_data['name'].str.contains(\"bot|Bot|BOT\"), 'name_bot'] = 1\n",
    "training_data.insert(6,'loc_bot',0)\n",
    "training_data.loc[pd.notnull(training_data['location']) & training_data['name'].str.contains(\"bot|Bot|BOT\"), 'loc_bot'] = 1\n",
    "training_data.insert(7,'screen_bot',0)\n",
    "training_data.loc[pd.notnull(training_data['screen_name']) & training_data['name'].str.contains(\"bot|Bot|BOT\"), 'screen_bot'] = 1\n",
    "def f(x, y, z, r):\n",
    "    return x+y+z+r\n",
    "training_data.insert(8,'contain_bot',0)\n",
    "training_data['contain_bot'] = np.vectorize(f)(training_data['des_bot'], training_data['name_bot'], training_data['loc_bot'], training_data['screen_bot'])\n",
    "\n",
    "training_data['verified'] = np.vectorize(tf)(training_data['verified']).astype(int)\n",
    "training_data['default_profile'] = np.vectorize(tf)(training_data['default_profile']).astype(int)\n",
    "training_data['default_profile_image'] = np.vectorize(tf)(training_data['default_profile_image']).astype(int)\n",
    "training_data['has_extended_profile'] = np.vectorize(tf)(training_data['has_extended_profile']).astype(int)\n",
    "\n",
    "training_data['followers_count'] = training_data['followers_count'].fillna(training_data['followers_count'].mean())\n",
    "training_data['friends_count'] = training_data['friends_count'].fillna(training_data['friends_count'].mean())\n",
    "training_data['listedcount'] = training_data['listedcount'].fillna(training_data['listedcount'].mean())\n",
    "training_data['favourites_count'] = training_data['favourites_count'].fillna(training_data['favourites_count'].mean())\n",
    "training_data['statuses_count'] = training_data['statuses_count'].fillna(training_data['statuses_count'].mean())\n",
    "\n",
    "training_data['followers_count'] = training_data['followers_count'].map(lambda x: np.log10(x+1))\n",
    "training_data['friends_count'] = training_data['friends_count'].map(lambda x: np.log10(x+1))\n",
    "training_data['listedcount'] = training_data['listedcount'].map(lambda x: np.log10(x+1))\n",
    "training_data['favourites_count'] = training_data['favourites_count'].map(lambda x: np.log10(x+1))\n",
    "training_data['statuses_count'] = training_data['statuses_count'].map(lambda x: np.log10(x+1))\n",
    "\n",
    "# training_data = training_data[['loc_bot','name_bot','des_bot','screen_bot','contain_bot','followers_count','friends_count','listedcount','favourites_count','verified','statuses_count','default_profile','default_profile_image','has_extended_profile','bot']]\n",
    "\n",
    "training_data = training_data[['loc_bot','name_bot','des_bot','screen_bot','contain_bot','followers_count','friends_count','statuses_count','verified','bot']]\n",
    "\n",
    "x = training_data.values \n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "training_data = pd.DataFrame(x_scaled)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "testing_data.insert(4,'des_bot',0)\n",
    "testing_data.loc[pd.notnull(testing_data['description']) & testing_data['description'].str.contains(\"bot|Bot|BOT\"), 'des_bot'] = 1\n",
    "testing_data.insert(5,'name_bot',0)\n",
    "testing_data.loc[pd.notnull(testing_data['name']) & testing_data['name'].str.contains(\"bot|Bot|BOT\"), 'name_bot'] = 1\n",
    "testing_data.insert(6,'loc_bot',0)\n",
    "testing_data.loc[pd.notnull(testing_data['location']) & testing_data['location'].str.contains(\"bot|Bot|BOT\"), 'loc_bot'] = 1\n",
    "testing_data.insert(7,'screen_bot',0)\n",
    "testing_data.loc[pd.notnull(testing_data['screen_name']) & testing_data['screen_name'].str.contains(\"bot|Bot|BOT\"), 'screen_bot'] = 1\n",
    "testing_data.insert(8,'contain_bot',0)\n",
    "testing_data['contain_bot'] = np.vectorize(f)(testing_data['des_bot'], testing_data['name_bot'], testing_data['loc_bot'],  testing_data['screen_bot'])\n",
    "\n",
    "testing_data['verified'] = np.vectorize(tf)(testing_data['verified']).astype(int)\n",
    "testing_data['default_profile'] = np.vectorize(tf)(testing_data['default_profile']).astype(int)\n",
    "testing_data['default_profile_image'] = np.vectorize(tf)(testing_data['default_profile_image']).astype(int)\n",
    "testing_data['has_extended_profile'] = np.vectorize(tf)(testing_data['has_extended_profile']).astype(int)\n",
    "\n",
    "testing_data['followers_count'] = pd.to_numeric(testing_data['followers_count'], errors = 'coerce')\n",
    "testing_data['followers_count'] = testing_data['followers_count'].fillna(testing_data['followers_count'].mean())\n",
    "testing_data['friends_count'] = pd.to_numeric(testing_data['friends_count'], errors = 'coerce')\n",
    "testing_data['friends_count'] = testing_data['friends_count'].fillna(testing_data['friends_count'].mean())\n",
    "testing_data['listed_count'] = pd.to_numeric(testing_data['listed_count'], errors = 'coerce')\n",
    "testing_data['listed_count'] = testing_data['listed_count'].fillna(testing_data['listed_count'].mean())\n",
    "testing_data['favorites_count'] = pd.to_numeric(testing_data['favorites_count'], errors = 'coerce')\n",
    "testing_data['favorites_count'] = testing_data['favorites_count'].fillna(testing_data['favorites_count'].mean())\n",
    "testing_data['statuses_count'] = pd.to_numeric(testing_data['statuses_count'], errors = 'coerce')\n",
    "testing_data['statuses_count'] = testing_data['statuses_count'].fillna(testing_data['statuses_count'].mean())\n",
    "\n",
    "\n",
    "testing_data['followers_count'] = testing_data['followers_count'].map(lg)\n",
    "testing_data['friends_count'] = testing_data['friends_count'].map(lg)\n",
    "testing_data['listed_count'] = testing_data['listed_count'].map(lg)\n",
    "testing_data['favorites_count'] = testing_data['favorites_count'].map(lg)\n",
    "testing_data['statuses_count'] = testing_data['statuses_count'].map(lg)\n",
    "\n",
    "# testing_data = testing_data[['loc_bot','name_bot','des_bot','screen_bot','contain_bot','followers_count','friends_count','listed_count','favorites_count','verified','statuses_count','default_profile','has_extended_profile','default_profile_image']]\n",
    "\n",
    "testing_data = testing_data[['loc_bot','name_bot','des_bot','screen_bot','contain_bot','followers_count','friends_count','statuses_count','verified']]\n",
    "\n",
    "y = testing_data.values \n",
    "y_scaled = min_max_scaler.fit_transform(y)\n",
    "testing_data = pd.DataFrame(y_scaled)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "X_train = training_data[training_data.columns[0:-1]]\n",
    "# pca = PCA(n_components=7)\n",
    "# pca.fit(X)\n",
    "# X = pca.transform(X)\n",
    "y_train = training_data[training_data.columns[-1]]\n",
    "\n",
    "X_test = testing_data\n",
    "\n",
    "\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=10)\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "pred_knn = knn_classifier.predict(X_test)\n",
    "result['bot'] = pred_knn\n",
    "result = result.astype(int)\n",
    "pd.DataFrame(result).to_csv('pred_knn_new.csv', sep=',', index = False)\n",
    "\n",
    "svm_classifier = svm.LinearSVC(penalty='l2', loss='squared_hinge', dual=True, tol=1e-4)\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "pred_svm = svm_classifier.predict(X_test)\n",
    "\n",
    "rt_classifier = RandomForestClassifier(n_estimators=10, max_depth = 7, min_samples_leaf = 3)\n",
    "rt_classifier = rt_classifier.fit(X_train, y_train)\n",
    "pred_rt = rt_classifier.predict(X_test)\n",
    "result['bot'] = pred_rt\n",
    "result = result.astype(int)\n",
    "pd.DataFrame(result).to_csv('pred_rt.csv', sep=',', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
